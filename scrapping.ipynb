{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "\n",
    "\n",
    "class Random:\n",
    "    def __init__(self, AuthorsFile, LanguagesFile, TypesFile):\n",
    "        self.Authors = self.readFile(AuthorsFile)\n",
    "        self.Languages = self.readFile(LanguagesFile)\n",
    "        self.Types = self.readFile(TypesFile)\n",
    "\n",
    "    def readFile(self, path):\n",
    "        f = open(path, \"r\", encoding=\"utf8\")\n",
    "        lst = f.read().splitlines()\n",
    "        f.close()\n",
    "        return lst\n",
    "\n",
    "    def GetID(self):\n",
    "        c = \"\"\n",
    "        for i in range(5):\n",
    "            c += chr(random.randint(65, 90))\n",
    "        return c + str(random.randint(10000, 99999))\n",
    "\n",
    "    def GetAuthor(self):\n",
    "        return self.Authors[random.randint(0, len(self.Authors) - 1)]\n",
    "\n",
    "    def Getlanguage(self):\n",
    "        return self.Languages[random.randint(0, len(self.Languages) - 1)]\n",
    "\n",
    "    def GetType(self):\n",
    "        return self.Types[random.randint(0, len(self.Types) - 1)]\n",
    "\n",
    "    def GetPrice(self):\n",
    "        return random.randint(1000, 9999)\n",
    "\n",
    "    def GetPages(self):\n",
    "        return random.randint(100, 5000)\n",
    "\n",
    "\n",
    "r = Random(r\"TextFiles\\Authors.txt\", r\"TextFiles\\languages.txt\", r\"TextFiles\\Types.txt\")\n",
    "\n",
    "f = open(r\"TextFiles\\links.txt\", \"r\")\n",
    "links = f.read().splitlines()\n",
    "f.close()\n",
    "\n",
    "f = open(r\"TextFiles\\data.txt\", \"r\")\n",
    "data = f.read().splitlines()\n",
    "f.close()\n",
    "start = int(data[0])\n",
    "counter = int(data[1])\n",
    "\n",
    "link = r\"https://archive.org/details/\"\n",
    "driverPath = r'C:\\ProgramData\\Anaconda3\\chromedriver.exe'\n",
    "driver = webdriver.Chrome(driverPath)\n",
    "half = len(links) // 2\n",
    "\n",
    "for j in range(start, half + 1):\n",
    "    for i in range(counter, -1, -1):\n",
    "\n",
    "        Names = []\n",
    "        Ids = []\n",
    "        Prices = []\n",
    "        Pages = []\n",
    "        Authors = []\n",
    "        Languages = []\n",
    "        Types = []\n",
    "\n",
    "        driver.get(link + links[j] + str(i))\n",
    "        content = driver.page_source\n",
    "        soup = BeautifulSoup(content)\n",
    "        for k in soup.findAll(class_=\"item-ia hov\"):\n",
    "            name = (k.find(\"div\", class_=\"ttl\")).text\n",
    "            if name != \"\":\n",
    "                Names.append(((name.replace(\"\\n\", \"\")).replace('\"', '')).strip())\n",
    "                Ids.append(r.GetID())\n",
    "                Prices.append(r.GetPrice())\n",
    "                Pages.append(r.GetPages())\n",
    "                Authors.append(r.GetAuthor())\n",
    "                Languages.append(r.Getlanguage())\n",
    "                Types.append(r.GetType())\n",
    "\n",
    "\n",
    "        df = pd.DataFrame({'Name': Names, 'ID': Ids, 'Price': Prices, 'Pages': Pages, 'Author': Authors, \"Language\": Languages, 'Type': Types})\n",
    "        df.to_csv('books.csv', index=False, encoding='utf-8', mode=\"a\", header= False)\n",
    "\n",
    "        f = open(r\"TextFiles\\data.txt\", \"w\")\n",
    "        f.writelines([str(j) , \"\\n\", str(i - 1), \"\\n\"])\n",
    "        f.close()\n",
    "    counter = 133\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
